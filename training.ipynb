{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Essential Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: setuptools in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Maturity</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Bid Price</th>\n",
       "      <th>Bid Size</th>\n",
       "      <th>Ask Price</th>\n",
       "      <th>Ask Size</th>\n",
       "      <th>Undl Price</th>\n",
       "      <th>date_id</th>\n",
       "      <th>...</th>\n",
       "      <th>exposure_22</th>\n",
       "      <th>exposure_23</th>\n",
       "      <th>exposure_24</th>\n",
       "      <th>exposure_25</th>\n",
       "      <th>exposure_26</th>\n",
       "      <th>exposure_27</th>\n",
       "      <th>exposure_28</th>\n",
       "      <th>exposure_29</th>\n",
       "      <th>exposure_30</th>\n",
       "      <th>exposure_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>518.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>13</td>\n",
       "      <td>1.76</td>\n",
       "      <td>592</td>\n",
       "      <td>518.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>519.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>54</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1619</td>\n",
       "      <td>518.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>94</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2646</td>\n",
       "      <td>518.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>521.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>479</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3311</td>\n",
       "      <td>518.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1207</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3614</td>\n",
       "      <td>518.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28571</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>442.06</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>18.12446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28572</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>442.06</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>18.12446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28573</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>442.06</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>18.12446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28574</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>442.06</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>18.12446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28575</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>442.06</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>18.12446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28576 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol    Maturity  Strike  Bid Price  Bid Size  Ask Price  \\\n",
       "0      2024-04-11    SPY  2024-04-12   518.0       1.74        13       1.76   \n",
       "1      2024-04-11    SPY  2024-04-12   519.0       1.24        54       1.25   \n",
       "2      2024-04-11    SPY  2024-04-12   520.0       0.84        94       0.85   \n",
       "3      2024-04-11    SPY  2024-04-12   521.0       0.54       479       0.55   \n",
       "4      2024-04-11    SPY  2024-04-12   522.0       0.33      1207       0.34   \n",
       "...           ...    ...         ...     ...        ...       ...        ...   \n",
       "28571  2024-05-10    QQQ  2024-05-21   440.0       0.00         0       0.00   \n",
       "28572  2024-05-10    QQQ  2024-05-21   441.0       0.00         0       0.00   \n",
       "28573  2024-05-10    QQQ  2024-05-22   440.0       0.00         0       0.00   \n",
       "28574  2024-05-10    QQQ  2024-05-22   441.0       0.00         0       0.00   \n",
       "28575  2024-05-10    QQQ  2024-05-23   441.0       0.00         0       0.00   \n",
       "\n",
       "       Ask Size  Undl Price  date_id  ...  exposure_22  exposure_23  \\\n",
       "0           592      518.00        1  ...      0.00000          NaN   \n",
       "1          1619      518.00        1  ...      0.00000          NaN   \n",
       "2          2646      518.00        1  ...      0.00000          NaN   \n",
       "3          3311      518.00        1  ...      0.00000          NaN   \n",
       "4          3614      518.00        1  ...      0.00000          NaN   \n",
       "...         ...         ...      ...  ...          ...          ...   \n",
       "28571         0      442.06       22  ...     18.12446          0.0   \n",
       "28572         0      442.06       22  ...     18.12446          0.0   \n",
       "28573         0      442.06       22  ...     18.12446          0.0   \n",
       "28574         0      442.06       22  ...     18.12446          0.0   \n",
       "28575         0      442.06       22  ...     18.12446          0.0   \n",
       "\n",
       "       exposure_24  exposure_25  exposure_26  exposure_27  exposure_28  \\\n",
       "0              NaN          NaN          NaN          NaN          NaN   \n",
       "1              NaN          NaN          NaN          NaN          NaN   \n",
       "2              NaN          NaN          NaN          NaN          NaN   \n",
       "3              NaN          NaN          NaN          NaN          NaN   \n",
       "4              NaN          NaN          NaN          NaN          NaN   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "28571          0.0          0.0          0.0          0.0          0.0   \n",
       "28572          0.0          0.0          0.0          0.0          0.0   \n",
       "28573          0.0          0.0          0.0          0.0          0.0   \n",
       "28574          0.0          0.0          0.0          0.0          0.0   \n",
       "28575          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "       exposure_29  exposure_30  exposure_31  \n",
       "0              NaN          NaN          NaN  \n",
       "1              NaN          NaN          NaN  \n",
       "2              NaN          NaN          NaN  \n",
       "3              NaN          NaN          NaN  \n",
       "4              NaN          NaN          NaN  \n",
       "...            ...          ...          ...  \n",
       "28571          NaN          NaN          NaN  \n",
       "28572          NaN          NaN          NaN  \n",
       "28573          0.0          NaN          NaN  \n",
       "28574          0.0          NaN          NaN  \n",
       "28575          0.0          0.0          NaN  \n",
       "\n",
       "[28576 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('BADSS_training_data_filled.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((8, 508.0, 'SPY'), {5, 6, 7}),\n",
       " ((8, 509.0, 'SPY'), {3, 4, 5, 6, 7}),\n",
       " ((8, 510.0, 'SPY'), {3, 4, 5, 6, 7}),\n",
       " ((8, 511.0, 'SPY'), {2, 3, 4, 5, 6, 7}),\n",
       " ((8, 512.0, 'SPY'), {2, 3, 4, 5, 6, 7}),\n",
       " ((8, 513.0, 'SPY'), {2, 3, 4, 5, 6, 7}),\n",
       " ((8, 514.0, 'SPY'), {2, 3, 4, 5, 6, 7}),\n",
       " ((8, 515.0, 'SPY'), {2, 3, 4, 5, 6, 7}),\n",
       " ((8, 516.0, 'SPY'), {2, 3, 4, 5, 6, 7}),\n",
       " ((8, 517.0, 'SPY'), {2, 3, 4, 5, 6, 7})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Maturity\"] = pd.to_datetime(df[\"Maturity\"])\n",
    "\n",
    "# Combine unique dates from \"Date\" and \"Maturity\", sort them, and remove duplicates\n",
    "unique_dates = pd.concat([df[\"Date\"], df[\"Maturity\"]]).sort_values().unique()\n",
    "# Create a mapping from each date to a unique sequential id (starting from 1)\n",
    "date_mapping = {date: i+1 for i, date in enumerate(unique_dates)}\n",
    "\n",
    "# Map the \"Date\" and \"Maturity\" columns to their corresponding ids using the mapping\n",
    "df[\"date_id\"] = df[\"Date\"].map(date_mapping)\n",
    "df[\"maturity_id\"] = df[\"Maturity\"].map(date_mapping)\n",
    "\n",
    "maturity_strike_symbol_dict = (\n",
    "    df.groupby([\"maturity_id\", \"Strike\", \"Symbol\"])[\"date_id\"]\n",
    "    .apply(set)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "list(maturity_strike_symbol_dict.items())[990:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Maturity</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Bid Price</th>\n",
       "      <th>Bid Size</th>\n",
       "      <th>Ask Price</th>\n",
       "      <th>Ask Size</th>\n",
       "      <th>Undl Price</th>\n",
       "      <th>date_id</th>\n",
       "      <th>...</th>\n",
       "      <th>exposure_24</th>\n",
       "      <th>exposure_25</th>\n",
       "      <th>exposure_26</th>\n",
       "      <th>exposure_27</th>\n",
       "      <th>exposure_28</th>\n",
       "      <th>exposure_29</th>\n",
       "      <th>exposure_30</th>\n",
       "      <th>exposure_31</th>\n",
       "      <th>maturity_id</th>\n",
       "      <th>exposure_1_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>506.0</td>\n",
       "      <td>6.23</td>\n",
       "      <td>1011</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1197</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>13.186584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>507.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>621</td>\n",
       "      <td>5.77</td>\n",
       "      <td>1248</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>12.582242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>508.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>868</td>\n",
       "      <td>5.26</td>\n",
       "      <td>1271</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>12.064889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>509.0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1114</td>\n",
       "      <td>4.78</td>\n",
       "      <td>1293</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>11.378884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>510.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1232</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1320</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>11.014251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>511.0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>1221</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1352</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>10.217236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>512.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1211</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1384</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>9.721190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>513.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1129</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1465</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>9.017258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>514.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1048</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1547</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>8.090856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>515.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1079</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1519</td>\n",
       "      <td>504.45</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>7.274242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbol   Maturity  Strike  Bid Price  Bid Size  Ask Price  \\\n",
       "1000 2024-04-15    SPY 2024-04-29   506.0       6.23      1011       6.30   \n",
       "1001 2024-04-15    SPY 2024-04-29   507.0       5.70       621       5.77   \n",
       "1002 2024-04-15    SPY 2024-04-29   508.0       5.19       868       5.26   \n",
       "1003 2024-04-15    SPY 2024-04-29   509.0       4.71      1114       4.78   \n",
       "1004 2024-04-15    SPY 2024-04-29   510.0       4.25      1232       4.31   \n",
       "1005 2024-04-15    SPY 2024-04-29   511.0       3.82      1221       3.89   \n",
       "1006 2024-04-15    SPY 2024-04-29   512.0       3.42      1211       3.48   \n",
       "1007 2024-04-15    SPY 2024-04-29   513.0       3.04      1129       3.10   \n",
       "1008 2024-04-15    SPY 2024-04-29   514.0       2.70      1048       2.76   \n",
       "1009 2024-04-15    SPY 2024-04-29   515.0       2.37      1079       2.43   \n",
       "\n",
       "      Ask Size  Undl Price  date_id  ...  exposure_24  exposure_25  \\\n",
       "1000      1197      504.45        3  ...          NaN          NaN   \n",
       "1001      1248      504.45        3  ...          NaN          NaN   \n",
       "1002      1271      504.45        3  ...          NaN          NaN   \n",
       "1003      1293      504.45        3  ...          NaN          NaN   \n",
       "1004      1320      504.45        3  ...          NaN          NaN   \n",
       "1005      1352      504.45        3  ...          NaN          NaN   \n",
       "1006      1384      504.45        3  ...          NaN          NaN   \n",
       "1007      1465      504.45        3  ...          NaN          NaN   \n",
       "1008      1547      504.45        3  ...          NaN          NaN   \n",
       "1009      1519      504.45        3  ...          NaN          NaN   \n",
       "\n",
       "      exposure_26  exposure_27  exposure_28  exposure_29  exposure_30  \\\n",
       "1000          NaN          NaN          NaN          NaN          NaN   \n",
       "1001          NaN          NaN          NaN          NaN          NaN   \n",
       "1002          NaN          NaN          NaN          NaN          NaN   \n",
       "1003          NaN          NaN          NaN          NaN          NaN   \n",
       "1004          NaN          NaN          NaN          NaN          NaN   \n",
       "1005          NaN          NaN          NaN          NaN          NaN   \n",
       "1006          NaN          NaN          NaN          NaN          NaN   \n",
       "1007          NaN          NaN          NaN          NaN          NaN   \n",
       "1008          NaN          NaN          NaN          NaN          NaN   \n",
       "1009          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "      exposure_31  maturity_id  exposure_1_ratio  \n",
       "1000          NaN           13         13.186584  \n",
       "1001          NaN           13         12.582242  \n",
       "1002          NaN           13         12.064889  \n",
       "1003          NaN           13         11.378884  \n",
       "1004          NaN           13         11.014251  \n",
       "1005          NaN           13         10.217236  \n",
       "1006          NaN           13          9.721190  \n",
       "1007          NaN           13          9.017258  \n",
       "1008          NaN           13          8.090856  \n",
       "1009          NaN           13          7.274242  \n",
       "\n",
       "[10 rows x 75 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for iterdate in range(1, 23):  # Loop over date_id values from 1 to 22\n",
    "    current_exposure_col = f\"exposure_{iterdate}\"  # Get the exposure column for the current date_id\n",
    "    current_PnL_col_ = f\"PnL_{iterdate}\"  # Get the PnL column for the current date_id\n",
    "\n",
    "    if current_exposure_col in df.columns:  # Check if the exposure column exists\n",
    "        # Compute denominator using the PnL column, add a small offset to avoid division by zero\n",
    "        denominator = -df[current_PnL_col_] + 0.0001\n",
    "        denominator = denominator.replace(0, np.nan)  # Replace zeros with NaN to avoid division errors\n",
    "\n",
    "        # For rows with the current date_id, calculate the ratio of exposure to the denominator\n",
    "        df.loc[df[\"date_id\"] == iterdate, \"exposure_1_ratio\"] = df.loc[df[\"date_id\"] == iterdate, current_exposure_col] / denominator\n",
    "\n",
    "# Display a slice of the DataFrame for inspection\n",
    "df[1000:1010]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the labeling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sort_key(row):\n",
    "    \"\"\"\n",
    "    Calculate the ratio = exposure_d / PnL_d, where d is the date_id for the row (avoiding division by zero).\n",
    "    Sorting rules:\n",
    "      - If ratio > 0, return f(r) = 1 - 1/(1 + r), mapping positive ratios to (0,1);\n",
    "      - If ratio < 0, return f(r) = 1 + 1/(1 - r), mapping negative ratios to (1,2);\n",
    "      - If ratio == 0, return 3.\n",
    "    This ensures that when sorting, positive ratios yield the smallest key, followed by negative values, and zeros come last.\n",
    "    \"\"\"\n",
    "    d = int(row[\"date_id\"])\n",
    "    # Dynamically fetch the corresponding exposure_d and PnL_d values\n",
    "    exposure_val = row.get(f\"exposure_{d}\", np.nan)\n",
    "    pnl_val = row.get(f\"PnL_{d}\", np.nan)\n",
    "    \n",
    "    # Avoid division by zero: if pnl_val is 0 or NaN, add a small offset\n",
    "    if pnl_val == 0 or np.isnan(pnl_val):\n",
    "        ratio = exposure_val / (pnl_val + 1e-3)\n",
    "    else:\n",
    "        ratio = exposure_val / pnl_val\n",
    "\n",
    "    if ratio > 0:\n",
    "        return 1 - 1 / (1 + ratio)\n",
    "    elif ratio < 0:\n",
    "        return 1 + 1 / (1 - ratio)\n",
    "    else:\n",
    "        return 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1 ...\n",
      "Epoch 1/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.1789\n",
      "Epoch 2/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1183\n",
      "Epoch 3/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1249 - val_loss: 0.1188\n",
      "Epoch 4/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1119 - val_loss: 0.0900\n",
      "Epoch 5/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1016 - val_loss: 0.0976\n",
      "Epoch 6/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0971 - val_loss: 0.0821\n",
      "Epoch 7/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.1043\n",
      "Epoch 8/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.0931\n",
      "Epoch 9/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0772\n",
      "Epoch 10/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0759\n",
      "Epoch 11/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0722\n",
      "Epoch 12/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0801\n",
      "Epoch 13/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0673\n",
      "Epoch 14/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0745\n",
      "Epoch 15/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0815\n",
      "Epoch 16/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0769\n",
      "Epoch 17/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0728\n",
      "Epoch 18/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0666\n",
      "Epoch 19/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0631\n",
      "Epoch 20/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0719\n",
      "Epoch 21/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.0572\n",
      "Epoch 22/256\n",
      "191/191 [==============================] - 0s 997us/step - loss: 0.0649 - val_loss: 0.0746\n",
      "Epoch 23/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0570\n",
      "Epoch 24/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0651 - val_loss: 0.0583\n",
      "Epoch 25/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0782\n",
      "Epoch 26/256\n",
      "191/191 [==============================] - 0s 972us/step - loss: 0.0621 - val_loss: 0.0701\n",
      "Epoch 27/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0558\n",
      "Epoch 28/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0606 - val_loss: 0.0584\n",
      "Epoch 29/256\n",
      "191/191 [==============================] - 0s 964us/step - loss: 0.0586 - val_loss: 0.0592\n",
      "Epoch 30/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0600\n",
      "Epoch 31/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0602 - val_loss: 0.0678\n",
      "Epoch 32/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0529\n",
      "Epoch 33/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0630\n",
      "Epoch 34/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0627\n",
      "Epoch 35/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0621\n",
      "Epoch 36/256\n",
      "191/191 [==============================] - 0s 974us/step - loss: 0.0528 - val_loss: 0.0499\n",
      "Epoch 37/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0592\n",
      "Epoch 38/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0490 - val_loss: 0.0557\n",
      "Epoch 39/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0532\n",
      "Epoch 40/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0544\n",
      "Epoch 41/256\n",
      "191/191 [==============================] - 0s 961us/step - loss: 0.0510 - val_loss: 0.0523\n",
      "Epoch 42/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.0493\n",
      "Epoch 43/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0464 - val_loss: 0.0493\n",
      "Epoch 44/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0579\n",
      "Epoch 45/256\n",
      "191/191 [==============================] - 0s 998us/step - loss: 0.0459 - val_loss: 0.0517\n",
      "Epoch 46/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0477 - val_loss: 0.0468\n",
      "Epoch 47/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0483\n",
      "Epoch 48/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0476\n",
      "Epoch 49/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0446\n",
      "Epoch 50/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0440\n",
      "Epoch 51/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0409\n",
      "Epoch 52/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0424 - val_loss: 0.0466\n",
      "Epoch 53/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0399 - val_loss: 0.0435\n",
      "Epoch 54/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0419\n",
      "Epoch 55/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0406\n",
      "Epoch 56/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0423\n",
      "Epoch 57/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0439\n",
      "Epoch 58/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.0423\n",
      "Epoch 59/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0449\n",
      "Epoch 60/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0425\n",
      "Epoch 61/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.0406\n",
      "Epoch 62/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0413\n",
      "Epoch 63/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0430\n",
      "Epoch 64/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0472\n",
      "Epoch 65/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.0435\n",
      "Epoch 66/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0321 - val_loss: 0.0408\n",
      "Epoch 67/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.0400\n",
      "Epoch 68/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.0422\n",
      "Epoch 69/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0401\n",
      "Epoch 70/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0381\n",
      "Epoch 71/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0316 - val_loss: 0.0414\n",
      "Epoch 72/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0309 - val_loss: 0.0433\n",
      "Epoch 73/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0375\n",
      "Epoch 74/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.0372\n",
      "Epoch 75/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0274 - val_loss: 0.0395\n",
      "Epoch 76/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0410\n",
      "Epoch 77/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0370\n",
      "Epoch 78/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.0379\n",
      "Epoch 79/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0290 - val_loss: 0.0396\n",
      "Epoch 80/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.0375\n",
      "Epoch 81/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0356\n",
      "Epoch 82/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0424\n",
      "Epoch 83/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0266 - val_loss: 0.0401\n",
      "Epoch 84/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0390\n",
      "Epoch 85/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0400\n",
      "Epoch 86/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0445\n",
      "Epoch 87/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0369\n",
      "Epoch 88/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0362\n",
      "Epoch 89/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.0413\n",
      "Epoch 90/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0381\n",
      "Epoch 91/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0376\n",
      "Epoch 92/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0362\n",
      "Epoch 93/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0383\n",
      "Epoch 94/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0354\n",
      "Epoch 95/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.0386\n",
      "Epoch 96/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0377\n",
      "Epoch 97/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0373\n",
      "Epoch 98/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0386\n",
      "Epoch 99/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0359\n",
      "Epoch 100/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0383\n",
      "Epoch 101/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0386\n",
      "Epoch 102/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0201 - val_loss: 0.0398\n",
      "Epoch 103/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0358\n",
      "Epoch 104/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0205 - val_loss: 0.0364\n",
      "Epoch 105/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0361\n",
      "Epoch 106/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0191 - val_loss: 0.0358\n",
      "Epoch 107/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0375\n",
      "Epoch 108/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0377\n",
      "Epoch 109/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0375\n",
      "Epoch 110/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0183 - val_loss: 0.0353\n",
      "Epoch 111/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0365\n",
      "Epoch 112/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0344\n",
      "Epoch 113/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0184 - val_loss: 0.0372\n",
      "Epoch 114/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0386\n",
      "Epoch 115/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0193 - val_loss: 0.0367\n",
      "Epoch 116/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0383\n",
      "Epoch 117/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0169 - val_loss: 0.0391\n",
      "Epoch 118/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0365\n",
      "Epoch 119/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0367\n",
      "Epoch 120/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0360\n",
      "Epoch 121/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0382\n",
      "Epoch 122/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0369\n",
      "Epoch 123/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0360\n",
      "Epoch 124/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0154 - val_loss: 0.0382\n",
      "Epoch 125/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0380\n",
      "Epoch 126/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0372\n",
      "Epoch 127/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0382\n",
      "Epoch 128/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0145 - val_loss: 0.0375\n",
      "Epoch 129/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0150 - val_loss: 0.0375\n",
      "Epoch 130/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0379\n",
      "Epoch 131/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0380\n",
      "Epoch 132/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0396\n",
      "Epoch 133/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0143 - val_loss: 0.0381\n",
      "Epoch 134/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0376\n",
      "Epoch 135/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0391\n",
      "Epoch 136/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0379\n",
      "Epoch 137/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0141 - val_loss: 0.0360\n",
      "Epoch 138/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0136 - val_loss: 0.0381\n",
      "Epoch 139/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0400\n",
      "Epoch 140/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0133 - val_loss: 0.0366\n",
      "Epoch 141/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0133 - val_loss: 0.0376\n",
      "Epoch 142/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0383\n",
      "Epoch 143/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0129 - val_loss: 0.0380\n",
      "Epoch 144/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0126 - val_loss: 0.0373\n",
      "Epoch 145/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0386\n",
      "Epoch 146/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0131 - val_loss: 0.0392\n",
      "Epoch 147/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0133 - val_loss: 0.0387\n",
      "Epoch 148/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0388\n",
      "Epoch 149/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0125 - val_loss: 0.0391\n",
      "Epoch 150/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0370\n",
      "Epoch 151/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0123 - val_loss: 0.0391\n",
      "Epoch 152/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0391\n",
      "Epoch 153/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0118 - val_loss: 0.0385\n",
      "Epoch 154/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0408\n",
      "Epoch 155/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0120 - val_loss: 0.0390\n",
      "Epoch 156/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0381\n",
      "Epoch 157/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0391\n",
      "Epoch 158/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0383\n",
      "Epoch 159/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0374\n",
      "Epoch 160/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0391\n",
      "Epoch 161/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0385\n",
      "Epoch 162/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0113 - val_loss: 0.0401\n",
      "Epoch 163/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0376\n",
      "Epoch 164/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0111 - val_loss: 0.0377\n",
      "Epoch 165/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0112 - val_loss: 0.0388\n",
      "Epoch 166/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0381\n",
      "Epoch 167/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0382\n",
      "Epoch 168/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0381\n",
      "Epoch 169/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0400\n",
      "Epoch 170/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0384\n",
      "Epoch 171/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0377\n",
      "Epoch 172/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0380\n",
      "Epoch 173/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0397\n",
      "Epoch 174/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0387\n",
      "Epoch 175/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0394\n",
      "Epoch 176/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0380\n",
      "Epoch 177/256\n",
      "191/191 [==============================] - 0s 969us/step - loss: 0.0104 - val_loss: 0.0389\n",
      "Epoch 178/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0399\n",
      "Epoch 179/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0103 - val_loss: 0.0384\n",
      "Epoch 180/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0390\n",
      "Epoch 181/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0393\n",
      "Epoch 182/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0385\n",
      "Epoch 183/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0396\n",
      "Epoch 184/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0382\n",
      "Epoch 185/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0377\n",
      "Epoch 186/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0383\n",
      "Epoch 187/256\n",
      "191/191 [==============================] - 0s 998us/step - loss: 0.0100 - val_loss: 0.0387\n",
      "Epoch 188/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0099 - val_loss: 0.0380\n",
      "Epoch 189/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0388\n",
      "Epoch 190/256\n",
      "191/191 [==============================] - 0s 956us/step - loss: 0.0097 - val_loss: 0.0393\n",
      "Epoch 191/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0385\n",
      "Epoch 192/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0097 - val_loss: 0.0382\n",
      "Epoch 193/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0387\n",
      "Epoch 194/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0096 - val_loss: 0.0386\n",
      "Epoch 195/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0389\n",
      "Epoch 196/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 197/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0393\n",
      "Epoch 198/256\n",
      "191/191 [==============================] - 0s 1000us/step - loss: 0.0095 - val_loss: 0.0374\n",
      "Epoch 199/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0385\n",
      "Epoch 200/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0392\n",
      "Epoch 201/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0382\n",
      "Epoch 202/256\n",
      "191/191 [==============================] - 0s 998us/step - loss: 0.0093 - val_loss: 0.0392\n",
      "Epoch 203/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0390\n",
      "Epoch 204/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0093 - val_loss: 0.0384\n",
      "Epoch 205/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0391\n",
      "Epoch 206/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0383\n",
      "Epoch 207/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0384\n",
      "Epoch 208/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0384\n",
      "Epoch 209/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0381\n",
      "Epoch 210/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0380\n",
      "Epoch 211/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0389\n",
      "Epoch 212/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0383\n",
      "Epoch 213/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0382\n",
      "Epoch 214/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0390\n",
      "Epoch 215/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0389\n",
      "Epoch 216/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0090 - val_loss: 0.0391\n",
      "Epoch 217/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0386\n",
      "Epoch 218/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0090 - val_loss: 0.0385\n",
      "Epoch 219/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0389\n",
      "Epoch 220/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0090 - val_loss: 0.0392\n",
      "Epoch 221/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0390\n",
      "Epoch 222/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0089 - val_loss: 0.0393\n",
      "Epoch 223/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0395\n",
      "Epoch 224/256\n",
      "191/191 [==============================] - 0s 983us/step - loss: 0.0089 - val_loss: 0.0392\n",
      "Epoch 225/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0388\n",
      "Epoch 226/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0089 - val_loss: 0.0385\n",
      "Epoch 227/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0392\n",
      "Epoch 228/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0088 - val_loss: 0.0389\n",
      "Epoch 229/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0387\n",
      "Epoch 230/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0088 - val_loss: 0.0391\n",
      "Epoch 231/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0387\n",
      "Epoch 232/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0088 - val_loss: 0.0390\n",
      "Epoch 233/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0393\n",
      "Epoch 234/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0087 - val_loss: 0.0389\n",
      "Epoch 235/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0389\n",
      "Epoch 236/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0087 - val_loss: 0.0392\n",
      "Epoch 237/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0393\n",
      "Epoch 238/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0394\n",
      "Epoch 239/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0392\n",
      "Epoch 240/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0086 - val_loss: 0.0392\n",
      "Epoch 241/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0395\n",
      "Epoch 242/256\n",
      "191/191 [==============================] - 0s 1000us/step - loss: 0.0085 - val_loss: 0.0389\n",
      "Epoch 243/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0395\n",
      "Epoch 244/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0391\n",
      "Epoch 245/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0394\n",
      "Epoch 246/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0392\n",
      "Epoch 247/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0390\n",
      "Epoch 248/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0085 - val_loss: 0.0389\n",
      "Epoch 249/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0391\n",
      "Epoch 250/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0390\n",
      "Epoch 251/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0394\n",
      "Epoch 252/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0390\n",
      "Epoch 253/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0393\n",
      "Epoch 254/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0388\n",
      "Epoch 255/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0393\n",
      "Epoch 256/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0084 - val_loss: 0.0393\n",
      "Fold 1 validation loss: 0.039252\n",
      "Training fold 2 ...\n",
      "Epoch 1/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.2072\n",
      "Epoch 2/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.1501 - val_loss: 0.1175\n",
      "Epoch 3/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1221 - val_loss: 0.1052\n",
      "Epoch 4/256\n",
      "191/191 [==============================] - 0s 972us/step - loss: 0.1138 - val_loss: 0.1212\n",
      "Epoch 5/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1080 - val_loss: 0.0929\n",
      "Epoch 6/256\n",
      "191/191 [==============================] - 0s 974us/step - loss: 0.0993 - val_loss: 0.1083\n",
      "Epoch 7/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.0885\n",
      "Epoch 8/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.1073\n",
      "Epoch 9/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.0825\n",
      "Epoch 10/256\n",
      "191/191 [==============================] - 0s 977us/step - loss: 0.0917 - val_loss: 0.0842\n",
      "Epoch 11/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0856\n",
      "Epoch 12/256\n",
      "191/191 [==============================] - 0s 977us/step - loss: 0.0815 - val_loss: 0.0700\n",
      "Epoch 13/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0814\n",
      "Epoch 14/256\n",
      "191/191 [==============================] - 0s 972us/step - loss: 0.0796 - val_loss: 0.0861\n",
      "Epoch 15/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0702\n",
      "Epoch 16/256\n",
      "191/191 [==============================] - 0s 970us/step - loss: 0.0761 - val_loss: 0.0822\n",
      "Epoch 17/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0789\n",
      "Epoch 18/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0765 - val_loss: 0.0696\n",
      "Epoch 19/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0671\n",
      "Epoch 20/256\n",
      "191/191 [==============================] - 0s 971us/step - loss: 0.0714 - val_loss: 0.0736\n",
      "Epoch 21/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0614\n",
      "Epoch 22/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0679 - val_loss: 0.0756\n",
      "Epoch 23/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0618\n",
      "Epoch 24/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0686 - val_loss: 0.0736\n",
      "Epoch 25/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0744\n",
      "Epoch 26/256\n",
      "191/191 [==============================] - 0s 970us/step - loss: 0.0633 - val_loss: 0.0631\n",
      "Epoch 27/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0613\n",
      "Epoch 28/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0625 - val_loss: 0.0611\n",
      "Epoch 29/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0658\n",
      "Epoch 30/256\n",
      "191/191 [==============================] - 0s 970us/step - loss: 0.0622 - val_loss: 0.0595\n",
      "Epoch 31/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0793\n",
      "Epoch 32/256\n",
      "191/191 [==============================] - 0s 967us/step - loss: 0.0604 - val_loss: 0.0579\n",
      "Epoch 33/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0636\n",
      "Epoch 34/256\n",
      "191/191 [==============================] - 0s 968us/step - loss: 0.0576 - val_loss: 0.0556\n",
      "Epoch 35/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0512\n",
      "Epoch 36/256\n",
      "191/191 [==============================] - 0s 969us/step - loss: 0.0530 - val_loss: 0.0544\n",
      "Epoch 37/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0449\n",
      "Epoch 38/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0516 - val_loss: 0.0610\n",
      "Epoch 39/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0546\n",
      "Epoch 40/256\n",
      "191/191 [==============================] - 0s 969us/step - loss: 0.0514 - val_loss: 0.0492\n",
      "Epoch 41/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0573\n",
      "Epoch 42/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0556\n",
      "Epoch 43/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.0451\n",
      "Epoch 44/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0508\n",
      "Epoch 45/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0458 - val_loss: 0.0520\n",
      "Epoch 46/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.0453\n",
      "Epoch 47/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0436 - val_loss: 0.0496\n",
      "Epoch 48/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0460\n",
      "Epoch 49/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0417 - val_loss: 0.0472\n",
      "Epoch 50/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0432\n",
      "Epoch 51/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0575\n",
      "Epoch 52/256\n",
      "191/191 [==============================] - 0s 997us/step - loss: 0.0426 - val_loss: 0.0577\n",
      "Epoch 53/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0477\n",
      "Epoch 54/256\n",
      "191/191 [==============================] - 0s 973us/step - loss: 0.0392 - val_loss: 0.0485\n",
      "Epoch 55/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0416\n",
      "Epoch 56/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0383 - val_loss: 0.0407\n",
      "Epoch 57/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0381\n",
      "Epoch 58/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0387 - val_loss: 0.0456\n",
      "Epoch 59/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0420\n",
      "Epoch 60/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0356 - val_loss: 0.0430\n",
      "Epoch 61/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0417\n",
      "Epoch 62/256\n",
      "191/191 [==============================] - 0s 974us/step - loss: 0.0357 - val_loss: 0.0475\n",
      "Epoch 63/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0512\n",
      "Epoch 64/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0369\n",
      "Epoch 65/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0330 - val_loss: 0.0391\n",
      "Epoch 66/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0405\n",
      "Epoch 67/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0339 - val_loss: 0.0407\n",
      "Epoch 68/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.0437\n",
      "Epoch 69/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0319 - val_loss: 0.0432\n",
      "Epoch 70/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.0398\n",
      "Epoch 71/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0338 - val_loss: 0.0445\n",
      "Epoch 72/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0423\n",
      "Epoch 73/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0315 - val_loss: 0.0409\n",
      "Epoch 74/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0424\n",
      "Epoch 75/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0427\n",
      "Epoch 76/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0491\n",
      "Epoch 77/256\n",
      "191/191 [==============================] - 0s 979us/step - loss: 0.0288 - val_loss: 0.0375\n",
      "Epoch 78/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.0429\n",
      "Epoch 79/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0396\n",
      "Epoch 80/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.0398\n",
      "Epoch 81/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.0414\n",
      "Epoch 82/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0278 - val_loss: 0.0427\n",
      "Epoch 83/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0378\n",
      "Epoch 84/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0257 - val_loss: 0.0410\n",
      "Epoch 85/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0367\n",
      "Epoch 86/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0386\n",
      "Epoch 87/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0406\n",
      "Epoch 88/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0408\n",
      "Epoch 89/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0247 - val_loss: 0.0417\n",
      "Epoch 90/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0391\n",
      "Epoch 91/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0382\n",
      "Epoch 92/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0419\n",
      "Epoch 93/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0426\n",
      "Epoch 94/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0407\n",
      "Epoch 95/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0402\n",
      "Epoch 96/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0379\n",
      "Epoch 97/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0387\n",
      "Epoch 98/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0224 - val_loss: 0.0396\n",
      "Epoch 99/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0409\n",
      "Epoch 100/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0220 - val_loss: 0.0418\n",
      "Epoch 101/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0403\n",
      "Epoch 102/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0389\n",
      "Epoch 103/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0387\n",
      "Epoch 104/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0432\n",
      "Epoch 105/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0396\n",
      "Epoch 106/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0377\n",
      "Epoch 107/256\n",
      "191/191 [==============================] - 0s 983us/step - loss: 0.0193 - val_loss: 0.0391\n",
      "Epoch 108/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0414\n",
      "Epoch 109/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0201 - val_loss: 0.0369\n",
      "Epoch 110/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0367\n",
      "Epoch 111/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0419\n",
      "Epoch 112/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0387\n",
      "Epoch 113/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0362\n",
      "Epoch 114/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0179 - val_loss: 0.0379\n",
      "Epoch 115/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0392\n",
      "Epoch 116/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0181 - val_loss: 0.0397\n",
      "Epoch 117/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0381\n",
      "Epoch 118/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0367\n",
      "Epoch 119/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0169 - val_loss: 0.0362\n",
      "Epoch 120/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0375\n",
      "Epoch 121/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0350\n",
      "Epoch 122/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0379\n",
      "Epoch 123/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0165 - val_loss: 0.0361\n",
      "Epoch 124/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0351\n",
      "Epoch 125/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0357\n",
      "Epoch 126/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0375\n",
      "Epoch 127/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0390\n",
      "Epoch 128/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0163 - val_loss: 0.0395\n",
      "Epoch 129/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0367\n",
      "Epoch 130/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0155 - val_loss: 0.0363\n",
      "Epoch 131/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0422\n",
      "Epoch 132/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0347\n",
      "Epoch 133/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0148 - val_loss: 0.0376\n",
      "Epoch 134/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0349\n",
      "Epoch 135/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0146 - val_loss: 0.0367\n",
      "Epoch 136/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0347\n",
      "Epoch 137/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0143 - val_loss: 0.0358\n",
      "Epoch 138/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0355\n",
      "Epoch 139/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0374\n",
      "Epoch 140/256\n",
      "191/191 [==============================] - 0s 972us/step - loss: 0.0138 - val_loss: 0.0347\n",
      "Epoch 141/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0360\n",
      "Epoch 142/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0359\n",
      "Epoch 143/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0375\n",
      "Epoch 144/256\n",
      "191/191 [==============================] - 0s 972us/step - loss: 0.0135 - val_loss: 0.0337\n",
      "Epoch 145/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0359\n",
      "Epoch 146/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0359\n",
      "Epoch 147/256\n",
      "191/191 [==============================] - 0s 983us/step - loss: 0.0134 - val_loss: 0.0356\n",
      "Epoch 148/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0369\n",
      "Epoch 149/256\n",
      "191/191 [==============================] - 0s 971us/step - loss: 0.0130 - val_loss: 0.0354\n",
      "Epoch 150/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0354\n",
      "Epoch 151/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0338\n",
      "Epoch 152/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0129 - val_loss: 0.0360\n",
      "Epoch 153/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0357\n",
      "Epoch 154/256\n",
      "191/191 [==============================] - 0s 974us/step - loss: 0.0123 - val_loss: 0.0341\n",
      "Epoch 155/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0353\n",
      "Epoch 156/256\n",
      "191/191 [==============================] - 0s 979us/step - loss: 0.0132 - val_loss: 0.0347\n",
      "Epoch 157/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0356\n",
      "Epoch 158/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0347\n",
      "Epoch 159/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0120 - val_loss: 0.0351\n",
      "Epoch 160/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0339\n",
      "Epoch 161/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0119 - val_loss: 0.0338\n",
      "Epoch 162/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0334\n",
      "Epoch 163/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0119 - val_loss: 0.0343\n",
      "Epoch 164/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0348\n",
      "Epoch 165/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0327\n",
      "Epoch 166/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0356\n",
      "Epoch 167/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0337\n",
      "Epoch 168/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0115 - val_loss: 0.0336\n",
      "Epoch 169/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0366\n",
      "Epoch 170/256\n",
      "191/191 [==============================] - 0s 973us/step - loss: 0.0115 - val_loss: 0.0346\n",
      "Epoch 171/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0336\n",
      "Epoch 172/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0343\n",
      "Epoch 173/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0113 - val_loss: 0.0333\n",
      "Epoch 174/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0334\n",
      "Epoch 175/256\n",
      "191/191 [==============================] - 0s 977us/step - loss: 0.0109 - val_loss: 0.0350\n",
      "Epoch 176/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0341\n",
      "Epoch 177/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0353\n",
      "Epoch 178/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0338\n",
      "Epoch 179/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0343\n",
      "Epoch 180/256\n",
      "191/191 [==============================] - 0s 977us/step - loss: 0.0109 - val_loss: 0.0342\n",
      "Epoch 181/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0340\n",
      "Epoch 182/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0336\n",
      "Epoch 183/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0107 - val_loss: 0.0342\n",
      "Epoch 184/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0339\n",
      "Epoch 185/256\n",
      "191/191 [==============================] - 0s 967us/step - loss: 0.0106 - val_loss: 0.0335\n",
      "Epoch 186/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0338\n",
      "Epoch 187/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0346\n",
      "Epoch 188/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0107 - val_loss: 0.0339\n",
      "Epoch 189/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0346\n",
      "Epoch 190/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0338\n",
      "Epoch 191/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0336\n",
      "Epoch 192/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0334\n",
      "Epoch 193/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0103 - val_loss: 0.0343\n",
      "Epoch 194/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0349\n",
      "Epoch 195/256\n",
      "191/191 [==============================] - 0s 970us/step - loss: 0.0101 - val_loss: 0.0341\n",
      "Epoch 196/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0335\n",
      "Epoch 197/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0101 - val_loss: 0.0332\n",
      "Epoch 198/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0335\n",
      "Epoch 199/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0338\n",
      "Epoch 200/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0102 - val_loss: 0.0340\n",
      "Epoch 201/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0337\n",
      "Epoch 202/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0099 - val_loss: 0.0339\n",
      "Epoch 203/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0346\n",
      "Epoch 204/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0335\n",
      "Epoch 205/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0098 - val_loss: 0.0342\n",
      "Epoch 206/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0336\n",
      "Epoch 207/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0335\n",
      "Epoch 208/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0341\n",
      "Epoch 209/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0339\n",
      "Epoch 210/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0097 - val_loss: 0.0341\n",
      "Epoch 211/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0345\n",
      "Epoch 212/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0338\n",
      "Epoch 213/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0097 - val_loss: 0.0341\n",
      "Epoch 214/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0336\n",
      "Epoch 215/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0095 - val_loss: 0.0348\n",
      "Epoch 216/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0339\n",
      "Epoch 217/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0347\n",
      "Epoch 218/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0337\n",
      "Epoch 219/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0338\n",
      "Epoch 220/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0095 - val_loss: 0.0338\n",
      "Epoch 221/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0338\n",
      "Epoch 222/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0343\n",
      "Epoch 223/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0094 - val_loss: 0.0336\n",
      "Epoch 224/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0335\n",
      "Epoch 225/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0339\n",
      "Epoch 226/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0343\n",
      "Epoch 227/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0346\n",
      "Epoch 228/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0344\n",
      "Epoch 229/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0094 - val_loss: 0.0339\n",
      "Epoch 230/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0339\n",
      "Epoch 231/256\n",
      "191/191 [==============================] - 0s 962us/step - loss: 0.0092 - val_loss: 0.0346\n",
      "Epoch 232/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0336\n",
      "Epoch 233/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0338\n",
      "Epoch 234/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0340\n",
      "Epoch 235/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0341\n",
      "Epoch 236/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0341\n",
      "Epoch 237/256\n",
      "191/191 [==============================] - 0s 983us/step - loss: 0.0091 - val_loss: 0.0339\n",
      "Epoch 238/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0341\n",
      "Epoch 239/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0342\n",
      "Epoch 240/256\n",
      "191/191 [==============================] - 0s 969us/step - loss: 0.0091 - val_loss: 0.0339\n",
      "Epoch 241/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0337\n",
      "Epoch 242/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0340\n",
      "Epoch 243/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0090 - val_loss: 0.0340\n",
      "Epoch 244/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0338\n",
      "Epoch 245/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0338\n",
      "Epoch 246/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0090 - val_loss: 0.0344\n",
      "Epoch 247/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0340\n",
      "Epoch 248/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0336\n",
      "Epoch 249/256\n",
      "191/191 [==============================] - 0s 997us/step - loss: 0.0089 - val_loss: 0.0342\n",
      "Epoch 250/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0339\n",
      "Epoch 251/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0341\n",
      "Epoch 252/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0338\n",
      "Epoch 253/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0340\n",
      "Epoch 254/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0089 - val_loss: 0.0337\n",
      "Epoch 255/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0338\n",
      "Epoch 256/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0341\n",
      "Fold 2 validation loss: 0.034138\n",
      "Training fold 3 ...\n",
      "Epoch 1/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.2023\n",
      "Epoch 2/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1508 - val_loss: 0.1238\n",
      "Epoch 3/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1216 - val_loss: 0.1010\n",
      "Epoch 4/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.1104 - val_loss: 0.1035\n",
      "Epoch 5/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1026 - val_loss: 0.1134\n",
      "Epoch 6/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0966 - val_loss: 0.0913\n",
      "Epoch 7/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.1005\n",
      "Epoch 8/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0935 - val_loss: 0.0969\n",
      "Epoch 9/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0925\n",
      "Epoch 10/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0886\n",
      "Epoch 11/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0843 - val_loss: 0.0874\n",
      "Epoch 12/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0908\n",
      "Epoch 13/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0836\n",
      "Epoch 14/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0764 - val_loss: 0.0829\n",
      "Epoch 15/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0815\n",
      "Epoch 16/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0774\n",
      "Epoch 17/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0728 - val_loss: 0.0740\n",
      "Epoch 18/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.0771\n",
      "Epoch 19/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0795\n",
      "Epoch 20/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0689 - val_loss: 0.0644\n",
      "Epoch 21/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0788\n",
      "Epoch 22/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0801\n",
      "Epoch 23/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0673 - val_loss: 0.0787\n",
      "Epoch 24/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0639\n",
      "Epoch 25/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.0734\n",
      "Epoch 26/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0687\n",
      "Epoch 27/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0652\n",
      "Epoch 28/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0632\n",
      "Epoch 29/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0603 - val_loss: 0.0613\n",
      "Epoch 30/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0551\n",
      "Epoch 31/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0719\n",
      "Epoch 32/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0534 - val_loss: 0.0608\n",
      "Epoch 33/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0611\n",
      "Epoch 34/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0646\n",
      "Epoch 35/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0520 - val_loss: 0.0625\n",
      "Epoch 36/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0584\n",
      "Epoch 37/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0565\n",
      "Epoch 38/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.0702\n",
      "Epoch 39/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0500 - val_loss: 0.0658\n",
      "Epoch 40/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.0579\n",
      "Epoch 41/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0595\n",
      "Epoch 42/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.0527\n",
      "Epoch 43/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0577\n",
      "Epoch 44/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0556\n",
      "Epoch 45/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.0558\n",
      "Epoch 46/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0609\n",
      "Epoch 47/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0648\n",
      "Epoch 48/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0529\n",
      "Epoch 49/256\n",
      "191/191 [==============================] - 0s 977us/step - loss: 0.0418 - val_loss: 0.0597\n",
      "Epoch 50/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0403 - val_loss: 0.0559\n",
      "Epoch 51/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0532\n",
      "Epoch 52/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0544\n",
      "Epoch 53/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0387 - val_loss: 0.0531\n",
      "Epoch 54/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0492\n",
      "Epoch 55/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0540\n",
      "Epoch 56/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0371 - val_loss: 0.0473\n",
      "Epoch 57/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0485\n",
      "Epoch 58/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0518\n",
      "Epoch 59/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0493\n",
      "Epoch 60/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0493\n",
      "Epoch 61/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0550\n",
      "Epoch 62/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0518\n",
      "Epoch 63/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0333 - val_loss: 0.0531\n",
      "Epoch 64/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0494\n",
      "Epoch 65/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0315 - val_loss: 0.0488\n",
      "Epoch 66/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0552\n",
      "Epoch 67/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0324 - val_loss: 0.0481\n",
      "Epoch 68/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0505\n",
      "Epoch 69/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0474\n",
      "Epoch 70/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0451\n",
      "Epoch 71/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0297 - val_loss: 0.0481\n",
      "Epoch 72/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.0484\n",
      "Epoch 73/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.0488\n",
      "Epoch 74/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0293 - val_loss: 0.0490\n",
      "Epoch 75/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.0479\n",
      "Epoch 76/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0278 - val_loss: 0.0448\n",
      "Epoch 77/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0468\n",
      "Epoch 78/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0270 - val_loss: 0.0468\n",
      "Epoch 79/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.0460\n",
      "Epoch 80/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.0468\n",
      "Epoch 81/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.0503\n",
      "Epoch 82/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0263 - val_loss: 0.0468\n",
      "Epoch 83/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0473\n",
      "Epoch 84/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0276 - val_loss: 0.0469\n",
      "Epoch 85/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0454\n",
      "Epoch 86/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.0494\n",
      "Epoch 87/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.0463\n",
      "Epoch 88/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0460\n",
      "Epoch 89/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.0497\n",
      "Epoch 90/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0450\n",
      "Epoch 91/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0491\n",
      "Epoch 92/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.0452\n",
      "Epoch 93/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0455\n",
      "Epoch 94/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0462\n",
      "Epoch 95/256\n",
      "191/191 [==============================] - 0s 997us/step - loss: 0.0224 - val_loss: 0.0433\n",
      "Epoch 96/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0454\n",
      "Epoch 97/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0422\n",
      "Epoch 98/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0474\n",
      "Epoch 99/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0456\n",
      "Epoch 100/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0430\n",
      "Epoch 101/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0471\n",
      "Epoch 102/256\n",
      "191/191 [==============================] - 0s 997us/step - loss: 0.0198 - val_loss: 0.0443\n",
      "Epoch 103/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0430\n",
      "Epoch 104/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0447\n",
      "Epoch 105/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0458\n",
      "Epoch 106/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0438\n",
      "Epoch 107/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0442\n",
      "Epoch 108/256\n",
      "191/191 [==============================] - 0s 1000us/step - loss: 0.0179 - val_loss: 0.0420\n",
      "Epoch 109/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0430\n",
      "Epoch 110/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0465\n",
      "Epoch 111/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0173 - val_loss: 0.0414\n",
      "Epoch 112/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0421\n",
      "Epoch 113/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0418\n",
      "Epoch 114/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0410\n",
      "Epoch 115/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0424\n",
      "Epoch 116/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0420\n",
      "Epoch 117/256\n",
      "191/191 [==============================] - 0s 994us/step - loss: 0.0160 - val_loss: 0.0438\n",
      "Epoch 118/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0459\n",
      "Epoch 119/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0426\n",
      "Epoch 120/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0411\n",
      "Epoch 121/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0429\n",
      "Epoch 122/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0409\n",
      "Epoch 123/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0147 - val_loss: 0.0415\n",
      "Epoch 124/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0391\n",
      "Epoch 125/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0408\n",
      "Epoch 126/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0150 - val_loss: 0.0409\n",
      "Epoch 127/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0408\n",
      "Epoch 128/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0404\n",
      "Epoch 129/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0141 - val_loss: 0.0425\n",
      "Epoch 130/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0408\n",
      "Epoch 131/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0411\n",
      "Epoch 132/256\n",
      "191/191 [==============================] - 0s 979us/step - loss: 0.0136 - val_loss: 0.0427\n",
      "Epoch 133/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0388\n",
      "Epoch 134/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0421\n",
      "Epoch 135/256\n",
      "191/191 [==============================] - 0s 978us/step - loss: 0.0128 - val_loss: 0.0390\n",
      "Epoch 136/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0419\n",
      "Epoch 137/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0407\n",
      "Epoch 138/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0128 - val_loss: 0.0412\n",
      "Epoch 139/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0398\n",
      "Epoch 140/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0420\n",
      "Epoch 141/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0129 - val_loss: 0.0391\n",
      "Epoch 142/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0406\n",
      "Epoch 143/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0409\n",
      "Epoch 144/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0116 - val_loss: 0.0394\n",
      "Epoch 145/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0388\n",
      "Epoch 146/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0414\n",
      "Epoch 147/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0406\n",
      "Epoch 148/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0393\n",
      "Epoch 149/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0395\n",
      "Epoch 150/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0114 - val_loss: 0.0393\n",
      "Epoch 151/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0393\n",
      "Epoch 152/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0400\n",
      "Epoch 153/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0111 - val_loss: 0.0409\n",
      "Epoch 154/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0388\n",
      "Epoch 155/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0399\n",
      "Epoch 156/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0414\n",
      "Epoch 157/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0390\n",
      "Epoch 158/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0423\n",
      "Epoch 159/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0390\n",
      "Epoch 160/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0419\n",
      "Epoch 161/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0106 - val_loss: 0.0419\n",
      "Epoch 162/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0389\n",
      "Epoch 163/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0397\n",
      "Epoch 164/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0397\n",
      "Epoch 165/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0102 - val_loss: 0.0397\n",
      "Epoch 166/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0406\n",
      "Epoch 167/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0395\n",
      "Epoch 168/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0104 - val_loss: 0.0402\n",
      "Epoch 169/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0398\n",
      "Epoch 170/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0398\n",
      "Epoch 171/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0403\n",
      "Epoch 172/256\n",
      "191/191 [==============================] - 0s 1000us/step - loss: 0.0097 - val_loss: 0.0399\n",
      "Epoch 173/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 174/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0389\n",
      "Epoch 175/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0405\n",
      "Epoch 176/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0387\n",
      "Epoch 177/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0417\n",
      "Epoch 178/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0095 - val_loss: 0.0401\n",
      "Epoch 179/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0402\n",
      "Epoch 180/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 181/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0396\n",
      "Epoch 182/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0092 - val_loss: 0.0395\n",
      "Epoch 183/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0404\n",
      "Epoch 184/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0398\n",
      "Epoch 185/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0401\n",
      "Epoch 186/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0403\n",
      "Epoch 187/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0398\n",
      "Epoch 188/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0393\n",
      "Epoch 189/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0398\n",
      "Epoch 190/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0393\n",
      "Epoch 191/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0394\n",
      "Epoch 192/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0389\n",
      "Epoch 193/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0403\n",
      "Epoch 194/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0400\n",
      "Epoch 195/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0395\n",
      "Epoch 196/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0401\n",
      "Epoch 197/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0402\n",
      "Epoch 198/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0398\n",
      "Epoch 199/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0390\n",
      "Epoch 200/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0393\n",
      "Epoch 201/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0401\n",
      "Epoch 202/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0399\n",
      "Epoch 203/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0409\n",
      "Epoch 204/256\n",
      "191/191 [==============================] - 0s 998us/step - loss: 0.0086 - val_loss: 0.0400\n",
      "Epoch 205/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0398\n",
      "Epoch 206/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0403\n",
      "Epoch 207/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0395\n",
      "Epoch 208/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0402\n",
      "Epoch 209/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0084 - val_loss: 0.0406\n",
      "Epoch 210/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0394\n",
      "Epoch 211/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0399\n",
      "Epoch 212/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0397\n",
      "Epoch 213/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0403\n",
      "Epoch 214/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0395\n",
      "Epoch 215/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0394\n",
      "Epoch 216/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0393\n",
      "Epoch 217/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0401\n",
      "Epoch 218/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0398\n",
      "Epoch 219/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0403\n",
      "Epoch 220/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0398\n",
      "Epoch 221/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0397\n",
      "Epoch 222/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0404\n",
      "Epoch 223/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0401\n",
      "Epoch 224/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0401\n",
      "Epoch 225/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0402\n",
      "Epoch 226/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0080 - val_loss: 0.0401\n",
      "Epoch 227/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0402\n",
      "Epoch 228/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0396\n",
      "Epoch 229/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0079 - val_loss: 0.0398\n",
      "Epoch 230/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0400\n",
      "Epoch 231/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0400\n",
      "Epoch 232/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0399\n",
      "Epoch 233/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0401\n",
      "Epoch 234/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0396\n",
      "Epoch 235/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0401\n",
      "Epoch 236/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0400\n",
      "Epoch 237/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0400\n",
      "Epoch 238/256\n",
      "191/191 [==============================] - 0s 991us/step - loss: 0.0079 - val_loss: 0.0401\n",
      "Epoch 239/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0398\n",
      "Epoch 240/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0398\n",
      "Epoch 241/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0399\n",
      "Epoch 242/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0400\n",
      "Epoch 243/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0402\n",
      "Epoch 244/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0396\n",
      "Epoch 245/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0399\n",
      "Epoch 246/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0401\n",
      "Epoch 247/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0401\n",
      "Epoch 248/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0400\n",
      "Epoch 249/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0397\n",
      "Epoch 250/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0401\n",
      "Epoch 251/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0397\n",
      "Epoch 252/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0401\n",
      "Epoch 253/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0400\n",
      "Epoch 254/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0399\n",
      "Epoch 255/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0400\n",
      "Epoch 256/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0401\n",
      "Fold 3 validation loss: 0.040125\n",
      "Training fold 4 ...\n",
      "Epoch 1/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.1475\n",
      "Epoch 2/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1426 - val_loss: 0.1289\n",
      "Epoch 3/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1217 - val_loss: 0.1622\n",
      "Epoch 4/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1051 - val_loss: 0.1165\n",
      "Epoch 5/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1006 - val_loss: 0.1301\n",
      "Epoch 6/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0973 - val_loss: 0.0860\n",
      "Epoch 7/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0878\n",
      "Epoch 8/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.1010\n",
      "Epoch 9/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0796\n",
      "Epoch 10/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0770\n",
      "Epoch 11/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.1264\n",
      "Epoch 12/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0931\n",
      "Epoch 13/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0838\n",
      "Epoch 14/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0795 - val_loss: 0.0733\n",
      "Epoch 15/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0775\n",
      "Epoch 16/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0680\n",
      "Epoch 17/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.0699\n",
      "Epoch 18/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0744\n",
      "Epoch 19/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0703 - val_loss: 0.0692\n",
      "Epoch 20/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0681\n",
      "Epoch 21/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0749\n",
      "Epoch 22/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0660 - val_loss: 0.0697\n",
      "Epoch 23/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0651\n",
      "Epoch 24/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0689\n",
      "Epoch 25/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0700\n",
      "Epoch 26/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0708\n",
      "Epoch 27/256\n",
      "191/191 [==============================] - 0s 984us/step - loss: 0.0593 - val_loss: 0.0625\n",
      "Epoch 28/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0662\n",
      "Epoch 29/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0648\n",
      "Epoch 30/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0634\n",
      "Epoch 31/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0644\n",
      "Epoch 32/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0621\n",
      "Epoch 33/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0629\n",
      "Epoch 34/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0611\n",
      "Epoch 35/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0632\n",
      "Epoch 36/256\n",
      "191/191 [==============================] - 0s 983us/step - loss: 0.0523 - val_loss: 0.0565\n",
      "Epoch 37/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.0558\n",
      "Epoch 38/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0561\n",
      "Epoch 39/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.0652\n",
      "Epoch 40/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0450 - val_loss: 0.0567\n",
      "Epoch 41/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0675\n",
      "Epoch 42/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0623\n",
      "Epoch 43/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0440 - val_loss: 0.0520\n",
      "Epoch 44/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0541\n",
      "Epoch 45/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0483\n",
      "Epoch 46/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0535\n",
      "Epoch 47/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0433 - val_loss: 0.0543\n",
      "Epoch 48/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0509\n",
      "Epoch 49/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0504\n",
      "Epoch 50/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0532\n",
      "Epoch 51/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0495\n",
      "Epoch 52/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0396 - val_loss: 0.0576\n",
      "Epoch 53/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0574\n",
      "Epoch 54/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0487\n",
      "Epoch 55/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0464\n",
      "Epoch 56/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0521\n",
      "Epoch 57/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0372 - val_loss: 0.0467\n",
      "Epoch 58/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0471\n",
      "Epoch 59/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0593\n",
      "Epoch 60/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0521\n",
      "Epoch 61/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0523\n",
      "Epoch 62/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0483\n",
      "Epoch 63/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0471\n",
      "Epoch 64/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.0505\n",
      "Epoch 65/256\n",
      "191/191 [==============================] - 0s 981us/step - loss: 0.0312 - val_loss: 0.0460\n",
      "Epoch 66/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0601\n",
      "Epoch 67/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0481\n",
      "Epoch 68/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.0510\n",
      "Epoch 69/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0490\n",
      "Epoch 70/256\n",
      "191/191 [==============================] - 0s 995us/step - loss: 0.0290 - val_loss: 0.0450\n",
      "Epoch 71/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0321 - val_loss: 0.0463\n",
      "Epoch 72/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0448\n",
      "Epoch 73/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0484\n",
      "Epoch 74/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.0448\n",
      "Epoch 75/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0279 - val_loss: 0.0445\n",
      "Epoch 76/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.0523\n",
      "Epoch 77/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.0478\n",
      "Epoch 78/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0282 - val_loss: 0.0423\n",
      "Epoch 79/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.0445\n",
      "Epoch 80/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0262 - val_loss: 0.0459\n",
      "Epoch 81/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0435\n",
      "Epoch 82/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0466\n",
      "Epoch 83/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.0427\n",
      "Epoch 84/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.0477\n",
      "Epoch 85/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0429\n",
      "Epoch 86/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0446\n",
      "Epoch 87/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0432\n",
      "Epoch 88/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0255 - val_loss: 0.0515\n",
      "Epoch 89/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0444\n",
      "Epoch 90/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0431\n",
      "Epoch 91/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0403\n",
      "Epoch 92/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0237 - val_loss: 0.0452\n",
      "Epoch 93/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0412\n",
      "Epoch 94/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0461\n",
      "Epoch 95/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.0403\n",
      "Epoch 96/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0221 - val_loss: 0.0406\n",
      "Epoch 97/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0415\n",
      "Epoch 98/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0423\n",
      "Epoch 99/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0412\n",
      "Epoch 100/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0380\n",
      "Epoch 101/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0201 - val_loss: 0.0403\n",
      "Epoch 102/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0421\n",
      "Epoch 103/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0224 - val_loss: 0.0383\n",
      "Epoch 104/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0435\n",
      "Epoch 105/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0387\n",
      "Epoch 106/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0393\n",
      "Epoch 107/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0463\n",
      "Epoch 108/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0208 - val_loss: 0.0382\n",
      "Epoch 109/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0422\n",
      "Epoch 110/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0443\n",
      "Epoch 111/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0390\n",
      "Epoch 112/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0425\n",
      "Epoch 113/256\n",
      "191/191 [==============================] - 0s 985us/step - loss: 0.0190 - val_loss: 0.0395\n",
      "Epoch 114/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0387\n",
      "Epoch 115/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0405\n",
      "Epoch 116/256\n",
      "191/191 [==============================] - 0s 989us/step - loss: 0.0178 - val_loss: 0.0388\n",
      "Epoch 117/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0385\n",
      "Epoch 118/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0393\n",
      "Epoch 119/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0406\n",
      "Epoch 120/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0404\n",
      "Epoch 121/256\n",
      "191/191 [==============================] - 0s 995us/step - loss: 0.0176 - val_loss: 0.0376\n",
      "Epoch 122/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0405\n",
      "Epoch 123/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0416\n",
      "Epoch 124/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0388\n",
      "Epoch 125/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0373\n",
      "Epoch 126/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0398\n",
      "Epoch 127/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0374\n",
      "Epoch 128/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0379\n",
      "Epoch 129/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0387\n",
      "Epoch 130/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0400\n",
      "Epoch 131/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0377\n",
      "Epoch 132/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0395\n",
      "Epoch 133/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0396\n",
      "Epoch 134/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0389\n",
      "Epoch 135/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0368\n",
      "Epoch 136/256\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0153 - val_loss: 0.0412\n",
      "Epoch 137/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0400\n",
      "Epoch 138/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0391\n",
      "Epoch 139/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0376\n",
      "Epoch 140/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0393\n",
      "Epoch 141/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0391\n",
      "Epoch 142/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0371\n",
      "Epoch 143/256\n",
      "191/191 [==============================] - 0s 975us/step - loss: 0.0146 - val_loss: 0.0380\n",
      "Epoch 144/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0376\n",
      "Epoch 145/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0380\n",
      "Epoch 146/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0386\n",
      "Epoch 147/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0373\n",
      "Epoch 148/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0140 - val_loss: 0.0379\n",
      "Epoch 149/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0360\n",
      "Epoch 150/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0391\n",
      "Epoch 151/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0384\n",
      "Epoch 152/256\n",
      "191/191 [==============================] - 0s 979us/step - loss: 0.0137 - val_loss: 0.0379\n",
      "Epoch 153/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0364\n",
      "Epoch 154/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0373\n",
      "Epoch 155/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0138 - val_loss: 0.0369\n",
      "Epoch 156/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0362\n",
      "Epoch 157/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0375\n",
      "Epoch 158/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0368\n",
      "Epoch 159/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0132 - val_loss: 0.0376\n",
      "Epoch 160/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0365\n",
      "Epoch 161/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0361\n",
      "Epoch 162/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0353\n",
      "Epoch 163/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0371\n",
      "Epoch 164/256\n",
      "191/191 [==============================] - 0s 980us/step - loss: 0.0131 - val_loss: 0.0371\n",
      "Epoch 165/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0373\n",
      "Epoch 166/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0369\n",
      "Epoch 167/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0362\n",
      "Epoch 168/256\n",
      "191/191 [==============================] - 0s 967us/step - loss: 0.0127 - val_loss: 0.0385\n",
      "Epoch 169/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0374\n",
      "Epoch 170/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0365\n",
      "Epoch 171/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0379\n",
      "Epoch 172/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0367\n",
      "Epoch 173/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0124 - val_loss: 0.0365\n",
      "Epoch 174/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0362\n",
      "Epoch 175/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0363\n",
      "Epoch 176/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0369\n",
      "Epoch 177/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0369\n",
      "Epoch 178/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0123 - val_loss: 0.0365\n",
      "Epoch 179/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0366\n",
      "Epoch 180/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0375\n",
      "Epoch 181/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0365\n",
      "Epoch 182/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0377\n",
      "Epoch 183/256\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0120 - val_loss: 0.0370\n",
      "Epoch 184/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0379\n",
      "Epoch 185/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0364\n",
      "Epoch 186/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0370\n",
      "Epoch 187/256\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0118 - val_loss: 0.0368\n",
      "Epoch 188/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0380\n",
      "Epoch 189/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0368\n",
      "Epoch 190/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0378\n",
      "Epoch 191/256\n",
      "191/191 [==============================] - 0s 979us/step - loss: 0.0118 - val_loss: 0.0371\n",
      "Epoch 192/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0370\n",
      "Epoch 193/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0383\n",
      "Epoch 194/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0370\n",
      "Epoch 195/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0368\n",
      "Epoch 196/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0374\n",
      "Epoch 197/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0367\n",
      "Epoch 198/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0375\n",
      "Epoch 199/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0371\n",
      "Epoch 200/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0112 - val_loss: 0.0369\n",
      "Epoch 201/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0376\n",
      "Epoch 202/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0369\n",
      "Epoch 203/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0372\n",
      "Epoch 204/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0375\n",
      "Epoch 205/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0364\n",
      "Epoch 206/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0373\n",
      "Epoch 207/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0371\n",
      "Epoch 208/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0372\n",
      "Epoch 209/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0372\n",
      "Epoch 210/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0369\n",
      "Epoch 211/256\n",
      "191/191 [==============================] - 0s 979us/step - loss: 0.0109 - val_loss: 0.0379\n",
      "Epoch 212/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0379\n",
      "Epoch 213/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0375\n",
      "Epoch 214/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0379\n",
      "Epoch 215/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0374\n",
      "Epoch 216/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0373\n",
      "Epoch 217/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0375\n",
      "Epoch 218/256\n",
      "191/191 [==============================] - 0s 982us/step - loss: 0.0108 - val_loss: 0.0378\n",
      "Epoch 219/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0375\n",
      "Epoch 220/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0379\n",
      "Epoch 221/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0375\n",
      "Epoch 222/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0377\n",
      "Epoch 223/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0377\n",
      "Epoch 224/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0382\n",
      "Epoch 225/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0378\n",
      "Epoch 226/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0374\n",
      "Epoch 227/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0376\n",
      "Epoch 228/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0373\n",
      "Epoch 229/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0382\n",
      "Epoch 230/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0383\n",
      "Epoch 231/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0381\n",
      "Epoch 232/256\n",
      "191/191 [==============================] - 0s 973us/step - loss: 0.0105 - val_loss: 0.0383\n",
      "Epoch 233/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0380\n",
      "Epoch 234/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0374\n",
      "Epoch 235/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0379\n",
      "Epoch 236/256\n",
      "191/191 [==============================] - 0s 986us/step - loss: 0.0104 - val_loss: 0.0380\n",
      "Epoch 237/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0378\n",
      "Epoch 238/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0376\n",
      "Epoch 239/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0378\n",
      "Epoch 240/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0380\n",
      "Epoch 241/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0377\n",
      "Epoch 242/256\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.0103 - val_loss: 0.0381\n",
      "Epoch 243/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0379\n",
      "Epoch 244/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0377\n",
      "Epoch 245/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0378\n",
      "Epoch 246/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0381\n",
      "Epoch 247/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0383\n",
      "Epoch 248/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0378\n",
      "Epoch 249/256\n",
      "191/191 [==============================] - 0s 977us/step - loss: 0.0102 - val_loss: 0.0378\n",
      "Epoch 250/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0376\n",
      "Epoch 251/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0376\n",
      "Epoch 252/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0102 - val_loss: 0.0379\n",
      "Epoch 253/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0378\n",
      "Epoch 254/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0379\n",
      "Epoch 255/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0378\n",
      "Epoch 256/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0381\n",
      "Fold 4 validation loss: 0.038076\n",
      "Training fold 5 ...\n",
      "Epoch 1/256\n",
      "191/191 [==============================] - 1s 1ms/step - loss: 0.3232 - val_loss: 0.1623\n",
      "Epoch 2/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1413 - val_loss: 0.1470\n",
      "Epoch 3/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1209 - val_loss: 0.1530\n",
      "Epoch 4/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.1182\n",
      "Epoch 5/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.1033 - val_loss: 0.1190\n",
      "Epoch 6/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.1166\n",
      "Epoch 7/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.1194\n",
      "Epoch 8/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.1002\n",
      "Epoch 9/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.0917\n",
      "Epoch 10/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0906\n",
      "Epoch 11/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0834\n",
      "Epoch 12/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0911\n",
      "Epoch 13/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0943\n",
      "Epoch 14/256\n",
      "191/191 [==============================] - 0s 998us/step - loss: 0.0763 - val_loss: 0.0838\n",
      "Epoch 15/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.1006\n",
      "Epoch 16/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0869\n",
      "Epoch 17/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0798\n",
      "Epoch 18/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0802\n",
      "Epoch 19/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0803\n",
      "Epoch 20/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.0778\n",
      "Epoch 21/256\n",
      "191/191 [==============================] - 0s 999us/step - loss: 0.0684 - val_loss: 0.0690\n",
      "Epoch 22/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0731\n",
      "Epoch 23/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0992\n",
      "Epoch 24/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0701\n",
      "Epoch 25/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0703\n",
      "Epoch 26/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.0743\n",
      "Epoch 27/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0630\n",
      "Epoch 28/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0777\n",
      "Epoch 29/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0674\n",
      "Epoch 30/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0721\n",
      "Epoch 31/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0699\n",
      "Epoch 32/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0626\n",
      "Epoch 33/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0791\n",
      "Epoch 34/256\n",
      "191/191 [==============================] - 0s 993us/step - loss: 0.0558 - val_loss: 0.0687\n",
      "Epoch 35/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0844\n",
      "Epoch 36/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0658\n",
      "Epoch 37/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0617\n",
      "Epoch 38/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0597\n",
      "Epoch 39/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0656\n",
      "Epoch 40/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0622\n",
      "Epoch 41/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0639\n",
      "Epoch 42/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0622\n",
      "Epoch 43/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0606\n",
      "Epoch 44/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0581\n",
      "Epoch 45/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.0619\n",
      "Epoch 46/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.0625\n",
      "Epoch 47/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0471 - val_loss: 0.0665\n",
      "Epoch 48/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0556\n",
      "Epoch 49/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.0579\n",
      "Epoch 50/256\n",
      "191/191 [==============================] - 0s 998us/step - loss: 0.0440 - val_loss: 0.0564\n",
      "Epoch 51/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0557\n",
      "Epoch 52/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0548\n",
      "Epoch 53/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0504\n",
      "Epoch 54/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0572\n",
      "Epoch 55/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0537\n",
      "Epoch 56/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0588\n",
      "Epoch 57/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0815\n",
      "Epoch 58/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0458 - val_loss: 0.0523\n",
      "Epoch 59/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0597\n",
      "Epoch 60/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0539\n",
      "Epoch 61/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0383 - val_loss: 0.0531\n",
      "Epoch 62/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0595\n",
      "Epoch 63/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0539\n",
      "Epoch 64/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0542\n",
      "Epoch 65/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0491\n",
      "Epoch 66/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0542\n",
      "Epoch 67/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0529\n",
      "Epoch 68/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0506\n",
      "Epoch 69/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0491\n",
      "Epoch 70/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0491\n",
      "Epoch 71/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0505\n",
      "Epoch 72/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0335 - val_loss: 0.0507\n",
      "Epoch 73/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0540\n",
      "Epoch 74/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0520\n",
      "Epoch 75/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0499\n",
      "Epoch 76/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0324 - val_loss: 0.0546\n",
      "Epoch 77/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0507\n",
      "Epoch 78/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0472\n",
      "Epoch 79/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0486\n",
      "Epoch 80/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0447\n",
      "Epoch 81/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0481\n",
      "Epoch 82/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0454\n",
      "Epoch 83/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0491\n",
      "Epoch 84/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0301 - val_loss: 0.0507\n",
      "Epoch 85/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0556\n",
      "Epoch 86/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.0466\n",
      "Epoch 87/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0285 - val_loss: 0.0458\n",
      "Epoch 88/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0510\n",
      "Epoch 89/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.0467\n",
      "Epoch 90/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.0473\n",
      "Epoch 91/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0461\n",
      "Epoch 92/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0272 - val_loss: 0.0437\n",
      "Epoch 93/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0274 - val_loss: 0.0453\n",
      "Epoch 94/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0276 - val_loss: 0.0453\n",
      "Epoch 95/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0436\n",
      "Epoch 96/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0436\n",
      "Epoch 97/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.0457\n",
      "Epoch 98/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.0474\n",
      "Epoch 99/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0472\n",
      "Epoch 100/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.0465\n",
      "Epoch 101/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0445\n",
      "Epoch 102/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0437\n",
      "Epoch 103/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0451\n",
      "Epoch 104/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0445\n",
      "Epoch 105/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0444\n",
      "Epoch 106/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0450\n",
      "Epoch 107/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0430\n",
      "Epoch 108/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0450\n",
      "Epoch 109/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0446\n",
      "Epoch 110/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0465\n",
      "Epoch 111/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0417\n",
      "Epoch 112/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0443\n",
      "Epoch 113/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.0436\n",
      "Epoch 114/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0415\n",
      "Epoch 115/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0434\n",
      "Epoch 116/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0422\n",
      "Epoch 117/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0412\n",
      "Epoch 118/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0435\n",
      "Epoch 119/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0435\n",
      "Epoch 120/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0428\n",
      "Epoch 121/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0412\n",
      "Epoch 122/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0425\n",
      "Epoch 123/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0425\n",
      "Epoch 124/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0432\n",
      "Epoch 125/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0434\n",
      "Epoch 126/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0412\n",
      "Epoch 127/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0432\n",
      "Epoch 128/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0430\n",
      "Epoch 129/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0450\n",
      "Epoch 130/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0431\n",
      "Epoch 131/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0420\n",
      "Epoch 132/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0409\n",
      "Epoch 133/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0422\n",
      "Epoch 134/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0429\n",
      "Epoch 135/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0438\n",
      "Epoch 136/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0431\n",
      "Epoch 137/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0428\n",
      "Epoch 138/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0424\n",
      "Epoch 139/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0423\n",
      "Epoch 140/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0413\n",
      "Epoch 141/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0415\n",
      "Epoch 142/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0429\n",
      "Epoch 143/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0422\n",
      "Epoch 144/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0429\n",
      "Epoch 145/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0428\n",
      "Epoch 146/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0438\n",
      "Epoch 147/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0439\n",
      "Epoch 148/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0426\n",
      "Epoch 149/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0426\n",
      "Epoch 150/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0431\n",
      "Epoch 151/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0421\n",
      "Epoch 152/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0433\n",
      "Epoch 153/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0425\n",
      "Epoch 154/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0422\n",
      "Epoch 155/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0435\n",
      "Epoch 156/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0427\n",
      "Epoch 157/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0427\n",
      "Epoch 158/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0419\n",
      "Epoch 159/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0420\n",
      "Epoch 160/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0422\n",
      "Epoch 161/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0427\n",
      "Epoch 162/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0419\n",
      "Epoch 163/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0437\n",
      "Epoch 164/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0436\n",
      "Epoch 165/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0424\n",
      "Epoch 166/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0413\n",
      "Epoch 167/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0428\n",
      "Epoch 168/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0425\n",
      "Epoch 169/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0424\n",
      "Epoch 170/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0429\n",
      "Epoch 171/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0422\n",
      "Epoch 172/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0416\n",
      "Epoch 173/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0424\n",
      "Epoch 174/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0430\n",
      "Epoch 175/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0423\n",
      "Epoch 176/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0429\n",
      "Epoch 177/256\n",
      "191/191 [==============================] - 0s 996us/step - loss: 0.0146 - val_loss: 0.0431\n",
      "Epoch 178/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0419\n",
      "Epoch 179/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0416\n",
      "Epoch 180/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0421\n",
      "Epoch 181/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0421\n",
      "Epoch 182/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0423\n",
      "Epoch 183/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0419\n",
      "Epoch 184/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0424\n",
      "Epoch 185/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0426\n",
      "Epoch 186/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0428\n",
      "Epoch 187/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0427\n",
      "Epoch 188/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0422\n",
      "Epoch 189/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0424\n",
      "Epoch 190/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0424\n",
      "Epoch 191/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0431\n",
      "Epoch 192/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0431\n",
      "Epoch 193/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0428\n",
      "Epoch 194/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0427\n",
      "Epoch 195/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0427\n",
      "Epoch 196/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0427\n",
      "Epoch 197/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0425\n",
      "Epoch 198/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0428\n",
      "Epoch 199/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0430\n",
      "Epoch 200/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0424\n",
      "Epoch 201/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0430\n",
      "Epoch 202/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0426\n",
      "Epoch 203/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0426\n",
      "Epoch 204/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0429\n",
      "Epoch 205/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0424\n",
      "Epoch 206/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0432\n",
      "Epoch 207/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0425\n",
      "Epoch 208/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0424\n",
      "Epoch 209/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0428\n",
      "Epoch 210/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0428\n",
      "Epoch 211/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0427\n",
      "Epoch 212/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0429\n",
      "Epoch 213/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0427\n",
      "Epoch 214/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0429\n",
      "Epoch 215/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0426\n",
      "Epoch 216/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0431\n",
      "Epoch 217/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0425\n",
      "Epoch 218/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0422\n",
      "Epoch 219/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0430\n",
      "Epoch 220/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0431\n",
      "Epoch 221/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0426\n",
      "Epoch 222/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0431\n",
      "Epoch 223/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0427\n",
      "Epoch 224/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0430\n",
      "Epoch 225/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0426\n",
      "Epoch 226/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0422\n",
      "Epoch 227/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0428\n",
      "Epoch 228/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0425\n",
      "Epoch 229/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0426\n",
      "Epoch 230/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0424\n",
      "Epoch 231/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0427\n",
      "Epoch 232/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0425\n",
      "Epoch 233/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0425\n",
      "Epoch 234/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0426\n",
      "Epoch 235/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0426\n",
      "Epoch 236/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0426\n",
      "Epoch 237/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0425\n",
      "Epoch 238/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0427\n",
      "Epoch 239/256\n",
      "191/191 [==============================] - 0s 988us/step - loss: 0.0127 - val_loss: 0.0424\n",
      "Epoch 240/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0426\n",
      "Epoch 241/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0425\n",
      "Epoch 242/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0427\n",
      "Epoch 243/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0428\n",
      "Epoch 244/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0426\n",
      "Epoch 245/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0426\n",
      "Epoch 246/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0428\n",
      "Epoch 247/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0427\n",
      "Epoch 248/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0426\n",
      "Epoch 249/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0425\n",
      "Epoch 250/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0425\n",
      "Epoch 251/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0425\n",
      "Epoch 252/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0425\n",
      "Epoch 253/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0425\n",
      "Epoch 254/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0426\n",
      "Epoch 255/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0426\n",
      "Epoch 256/256\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0426\n",
      "Fold 5 validation loss: 0.042616\n",
      "\n",
      "Best validation loss: 0.034138. Model saved as 'trained_model.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavin0576/miniforge3/envs/EECS127/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Data Preprocessing\n",
    "# ---------------------------\n",
    "# Generate labels based on your evaluation criteria (if needed)\n",
    "df[\"label\"] = df.apply(custom_sort_key, axis=1)\n",
    "\n",
    "# Define features\n",
    "features = ['date_id', 'maturity_id', 'Symbol', 'Strike', 'Bid Price', 'Bid Size', 'Ask Price', 'Ask Size']\n",
    "\n",
    "# Encode the 'Symbol' column\n",
    "le = LabelEncoder()\n",
    "df[\"Symbol_enc\"] = le.fit_transform(df[\"Symbol\"])\n",
    "features = ['date_id', 'maturity_id', 'Symbol_enc', 'Strike', 'Bid Price', 'Bid Size', 'Ask Price', 'Ask Size']\n",
    "\n",
    "# Construct the feature matrix and target vector\n",
    "X = df[features].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Define Model Building Function\n",
    "# ---------------------------\n",
    "def build_model(input_dim):\n",
    "    # Define an exponential decay learning rate schedule\n",
    "    lr_schedule = ExponentialDecay(\n",
    "        initial_learning_rate=0.01,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Single output for regression\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# ---------------------------\n",
    "# 3. 5-Fold Cross-Validation Training\n",
    "# ---------------------------\n",
    "num_epochs = 256\n",
    "batch_size = 120\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    print(f\"Training fold {fold} ...\")\n",
    "    X_train, X_val = X_scaled[train_index], X_scaled[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = build_model(input_dim=X_scaled.shape[1])\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=1)  # Set verbose to 1 to see the training progress\n",
    "    \n",
    "    # Retrieve the validation loss from the last epoch for this fold\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    print(f\"Fold {fold} validation loss: {val_loss:.6f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "    fold += 1\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Save the Model with the Best Validation Performance\n",
    "# ---------------------------\n",
    "best_model.save(\"trained_model.h5\")\n",
    "print(f\"\\nBest validation loss: {best_val_loss:.6f}. Model saved as 'trained_model.h5'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
